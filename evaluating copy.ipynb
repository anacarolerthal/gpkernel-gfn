{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac810e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "from functools import partial\n",
    "from utils import KernelFunction, KernelEnvironment\n",
    "from utils import plot_kernel_function, compare_kernels\n",
    "from gflownet import GFlowNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc86eab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61db28b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ForwardPolicy, BackwardPolicy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a90bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Sets the seed for reproducibility.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # For all GPUs\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # These two lines are for full reproducibility with CUDA\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# --- Call this at the start of your script ---\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c27061",
   "metadata": {},
   "outputs": [],
   "source": [
    "global reward_calls\n",
    "reward_calls = 0\n",
    "def log_likelihood_reward(X, Y, env: 'KernelEnvironment'):\n",
    "    \"\"\"\n",
    "    Computes the log marginal likelihood of each kernel in the environment\n",
    "    given the data (X, Y).\n",
    "    \"\"\"\n",
    "    global reward_calls\n",
    "    reward_calls += env.batch_size\n",
    "    rewards = []\n",
    "    for k in env.state: \n",
    "        log_likelihood = utils.evaluate_likelihood(k, X, Y)\n",
    "        #print(np.log(1 + np.exp(-0.5 * (log_likelihood - 5))))\n",
    "        reward = 1 / np.log(1 + np.exp(-0.05 * (log_likelihood))) \n",
    "        if reward < 1e-10:\n",
    "            print(\"Warning: Reward is too small, setting to 1e-10\")\n",
    "            reward = 1e-10\n",
    "        rewards.append(reward if log_likelihood is not None else 1e-10)\n",
    "        #print(reward, log_likelihood)\n",
    "        #rewards.append(log_likelihood**(3/2) if log_likelihood is not None else 1e-10)\n",
    "    return torch.tensor(rewards, dtype=torch.float32) \n",
    "\n",
    "def create_env(batch_size=64):\n",
    "    return KernelEnvironment(\n",
    "    batch_size=batch_size,\n",
    "    max_trajectory_length=MAX_LEN,\n",
    "    log_reward=log_reward_fn\n",
    ")\n",
    "\n",
    "def create_env(batch_size=64):\n",
    "    return KernelEnvironment(\n",
    "    batch_size=batch_size,\n",
    "    max_trajectory_length=MAX_LEN,\n",
    "    log_reward=log_reward_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cf9f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_hyperparameters(kernel: KernelFunction):\n",
    "    \"\"\"\n",
    "    Recursively traverses a KernelFunction object and randomly modifies the\n",
    "    hyperparameters of its base components in a reasonable range.\n",
    "    \n",
    "    Args:\n",
    "        kernel (KernelFunction): The kernel object to modify in-place.\n",
    "    \"\"\"\n",
    "    # Base case: If this is a base kernel (like RBF, Linear), modify its params.\n",
    "    # A base kernel has no children.\n",
    "    if not kernel.children:\n",
    "        if kernel.hyperparams:\n",
    "            print(f\"  -> Randomizing '{kernel.name}' params...\")\n",
    "            for param, value in kernel.hyperparams.items():\n",
    "                # Define a scaling factor to adjust the parameter.\n",
    "                # e.g., random.uniform(0.5, 1.5) will change the value\n",
    "                # by -50% to +50% of its original value.\n",
    "                scale_factor = random.uniform(0.5, 1.5)\n",
    "                new_value = value * scale_factor\n",
    "                \n",
    "                # Update the hyperparameter in the dictionary, rounding for neatness\n",
    "                kernel.hyperparams[param] = round(new_value, 3)\n",
    "\n",
    "    # Recursive step: If this is a composite kernel (Sum, Product),\n",
    "    # call this function on each of its children.\n",
    "    else:\n",
    "        for child in kernel.children:\n",
    "            randomize_hyperparameters(child)\n",
    "\n",
    "def create_random_kernel():\n",
    "    \"\"\"\n",
    "    Creates a random kernel function.\n",
    "    \"\"\"\n",
    "    # Create a series of actions from a uniform distribution\n",
    "    env = KernelEnvironment(\n",
    "        batch_size=1,\n",
    "        max_trajectory_length=4,\n",
    "        log_reward=log_likelihood_reward\n",
    "    )\n",
    "    n = env.action_space_size  \n",
    "    logits = torch.ones(n) \n",
    "   \n",
    "\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            #prevent the first action from being a stop (-1)\n",
    "            logits[-1] = -torch.inf\n",
    "            dist = Categorical(logits=logits)\n",
    "            actions = dist.sample((1,))  # Creates a 1D tensor of shape [1]\n",
    "        else:\n",
    "            logits[-1] = 1\n",
    "            dist = Categorical(logits=logits)\n",
    "            actions = dist.sample((1,)) # Creates a 1D tensor of shape [1]\n",
    "\n",
    "        env.apply(actions)\n",
    "    \n",
    "    KFn = env.state[0]\n",
    "    randomize_hyperparameters(KFn)\n",
    "    \n",
    "    return KFn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08a880fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Randomizing 'Constant' params...\n",
      "  -> Randomizing 'Constant' params...\n",
      "  -> Randomizing 'Periodic' params...\n",
      "True Kernel: ((Constant({'variance': 1.139}) * Constant({'variance': 0.525})) * Periodic({'period': 0.775, 'variance': 0.723, 'lengthscale': 1.236})) Log Marginal Likelihood: 77.55666898311783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f82a1f7f750>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ll = -1\n",
    "while ll < 0:\n",
    "    true_kernel = create_random_kernel()\n",
    "    X, Y, true_kernel_str = utils.generate_gp_data(true_kernel, input_dim=1, n_points=30, noise_var=1e-4)\n",
    "    X_test, Y_test, _ = utils.generate_gp_data(true_kernel, input_dim=1, n_points=50, noise_var=1e-4)\n",
    "    ll = utils.evaluate_likelihood(true_kernel, X, Y, runtime=False)\n",
    "\n",
    "print(\"True Kernel:\", true_kernel_str, \"Log Marginal Likelihood:\", utils.evaluate_likelihood(true_kernel, X, Y, runtime=False))\n",
    "\n",
    "plt.scatter(X, Y, color='black', s=10, label='Data Points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdfbe01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Randomizing 'Linear' params...\n",
      "  -> Randomizing 'Constant' params...\n",
      "  -> Randomizing 'Periodic' params...\n",
      "True Kernel: ((Linear({'variances': 1.177}) * Constant({'variance': 1.392})) * Periodic({'period': 0.587, 'variance': 0.922, 'lengthscale': 0.53})) Log Marginal Likelihood: 17.607937853316905\n"
     ]
    }
   ],
   "source": [
    "candidate_kernel = create_random_kernel()\n",
    "print(\"True Kernel:\", candidate_kernel, \"Log Marginal Likelihood:\", utils.evaluate_likelihood(candidate_kernel, X, Y, runtime=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "becd7077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train\n",
    "\n",
    "epochs = 100\n",
    "BATCH_SIZE = 256\n",
    "MAX_LEN = 4\n",
    "lr = 1e-3\n",
    "\n",
    "log_reward_fn = partial(log_likelihood_reward, X, Y)\n",
    "env = create_env()\n",
    "\n",
    "forward_model = ForwardPolicy(input_dim=MAX_LEN, output_dim=env.action_space_size, epsilon=0.5)\n",
    "backward_model = BackwardPolicy()\n",
    "criterion = 'db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b66a3d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26244"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 * env.action_space_size ** (5 -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c30a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s] /home/guilherme/miniconda3/envs/gpy_env/lib/python3.11/site-packages/GPy/kern/src/stationary.py:168: RuntimeWarning:overflow encountered in divide\n",
      " /home/guilherme/miniconda3/envs/gpy_env/lib/python3.11/site-packages/GPy/kern/src/rbf.py:52: RuntimeWarning:overflow encountered in square\n",
      " /home/guilherme/miniconda3/envs/gpy_env/lib/python3.11/site-packages/GPy/kern/src/rbf.py:178: RuntimeWarning:invalid value encountered in multiply\n",
      "  2%|â–         | 2/100 [00:38<29:07, 17.83s/it, loss=194]"
     ]
    }
   ],
   "source": [
    "gflownet = GFlowNet(\n",
    "    forward_flow=forward_model, \n",
    "    backward_flow=backward_model, \n",
    "    criterion=criterion \n",
    ")\n",
    "\n",
    "\n",
    "gflownet, losses = train(\n",
    "    gflownet=gflownet,\n",
    "    create_env=create_env,\n",
    "    epochs=epochs,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=lr,\n",
    "    min_eps=1e-2,\n",
    "    clamp_g= 1,\n",
    "    use_scheduler=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c2fef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sampling 25 kernels from the trained model...\n",
      "Sample 1: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n",
      "Sample 2: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n",
      "Sample 3: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n",
      "Sample 4: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n",
      "Sample 5: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n",
      "Sample 6: (((Linear({'variances': 1.0}) + RBF({'lengthscale': 1.0, 'variance': 1.0})) + RBF({'lengthscale': 1.0, 'variance': 1.0})) * RBF({'lengthscale': 1.0, 'variance': 1.0})), Reward: 2.0635321568167537, Log Likelihood: 9.4470\n",
      "Sample 7: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n",
      "Sample 8: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n",
      "Sample 9: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n",
      "Sample 10: Linear({'variances': 1.0}), Reward: 2.0981108625242824, Log Likelihood: 9.8656\n",
      "Sample 11: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n",
      "Sample 12: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n",
      "Sample 13: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n",
      "Sample 14: (RBF({'lengthscale': 1.0, 'variance': 1.0}) + RBF({'lengthscale': 1.0, 'variance': 1.0})), Reward: 2.3475611686271782, Log Likelihood: 12.6568\n",
      "Sample 15: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n",
      "Sample 16: Linear({'variances': 1.0}), Reward: 2.0981108625242824, Log Likelihood: 9.8656\n",
      "Sample 17: Linear({'variances': 1.0}), Reward: 2.0981108625242824, Log Likelihood: 9.8656\n",
      "Sample 18: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n",
      "Sample 19: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n",
      "Sample 20: Linear({'variances': 1.0}), Reward: 2.0981108625242824, Log Likelihood: 9.8656\n",
      "Sample 21: Linear({'variances': 1.0}), Reward: 2.0981108625242824, Log Likelihood: 9.8656\n",
      "Sample 22: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n",
      "Sample 23: Linear({'variances': 1.0}), Reward: 2.0981108625242824, Log Likelihood: 9.8656\n",
      "Sample 24: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n",
      "Sample 25: RBF({'lengthscale': 1.0, 'variance': 1.0}), Reward: 2.8560823960795, Log Likelihood: 17.3857\n"
     ]
    }
   ],
   "source": [
    "# --- Sampling from the Trained GFlowNet ---\n",
    "print(\"\\n Sampling 25 kernels from the trained model...\")\n",
    "eval_env = KernelEnvironment(\n",
    "    batch_size=25,\n",
    "    max_trajectory_length=MAX_LEN,\n",
    "    log_reward=log_reward_fn\n",
    ")\n",
    "\n",
    "gflownet.eval()\n",
    "final_batch_ll = gflownet.sample(eval_env)\n",
    "\n",
    "# Expect to see kernels with high log likelihood\n",
    "for i, kernel in enumerate(final_batch_ll.state):\n",
    "    print(f\"Sample {i+1}: {kernel}, Reward: {1 / np.log(1 + np.exp(-0.05 * (utils.evaluate_likelihood(kernel, X, Y))))}, Log Likelihood: {utils.evaluate_likelihood(kernel, X_test, Y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145bd33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique kernels sampled: 76\n"
     ]
    }
   ],
   "source": [
    "eval_env = KernelEnvironment(\n",
    "    batch_size=1000,\n",
    "    max_trajectory_length=MAX_LEN,\n",
    "    log_reward=log_reward_fn\n",
    ")\n",
    "\n",
    "gflownet.eval()\n",
    "final_batch_ll = gflownet.sample(eval_env)\n",
    "\n",
    "\n",
    "#Count different kernels AKA numbeer of modes\n",
    "kernel_counts = {}\n",
    "for kernel in final_batch_ll.state:\n",
    "    #only add the kernel if it is not already in the dictionary\n",
    "    kernel_str = str(kernel)\n",
    "    if kernel_str not in kernel_counts:\n",
    "        kernel_counts[kernel_str] = 1\n",
    "    else:\n",
    "        kernel_counts[kernel_str] += 1\n",
    "\n",
    "print(f\"Total number of unique kernels sampled: {len(kernel_counts)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b362a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "@torch.no_grad()\n",
    "def calculate_l1_distance(forward_policy: ForwardPolicy, env_class: KernelEnvironment, max_len: int, X, Y):\n",
    "    \"\"\"\n",
    "    Computes the L1 distance between the policy distribution and the target reward distribution.\n",
    "\n",
    "    Args:\n",
    "        forward_policy (ForwardPolicy): The trained forward policy model.\n",
    "        env_class (KernelEnvironment): The environment class (not an instance).\n",
    "        max_len (int): The maximum trajectory length.\n",
    "        X, Y: Data for computing the reward.\n",
    "\n",
    "    Returns:\n",
    "        float: The L1 distance.\n",
    "    \"\"\"\n",
    "    # This dictionary will store data for each unique terminal kernel.\n",
    "    # Key: string representation of the kernel\n",
    "    # Value: {'reward': float, 'policy_prob': float}\n",
    "    terminal_states_data = defaultdict(lambda: {'reward': 0.0, 'policy_prob': 0.0})\n",
    "\n",
    "    # We need a dummy env to get action space info\n",
    "    dummy_env = env_class(batch_size=1, max_trajectory_length=max_len, log_reward=None)\n",
    "    action_map = dummy_env.action_map\n",
    "    end_action_id = dummy_env.end_action_id\n",
    "\n",
    "    def _enumerate_and_calc_probs(env: KernelEnvironment, current_log_prob: float):\n",
    "        \"\"\"A recursive helper to explore all trajectories.\"\"\"\n",
    "        # Check if the current path has reached max length\n",
    "        if len(env.history[0]) >= max_len:\n",
    "            # This path is forced to terminate. Treat it as a terminal state.\n",
    "            kernel_str = str(env.state[0])\n",
    "            if terminal_states_data[kernel_str]['reward'] == 0.0:\n",
    "                 reward = log_likelihood_reward(X, Y, env).item()\n",
    "                 terminal_states_data[kernel_str]['reward'] = reward\n",
    "            \n",
    "            # Add the probability of this path to the kernel's total probability\n",
    "            terminal_states_data[kernel_str]['policy_prob'] += torch.exp(torch.tensor(current_log_prob)).item()\n",
    "            return\n",
    "\n",
    "        # Explore all valid actions from the current state\n",
    "        # The `forward` method gives us logits for all actions\n",
    "        _, _, all_logits, _ = forward_policy.net(env)   \n",
    "        \n",
    "        # Ensure we have a clean probability distribution over valid actions\n",
    "        dist = Categorical(logits=all_logits)\n",
    "\n",
    "        for action_id, (op, k_name) in action_map.items():\n",
    "            # Check if action is valid for the current state using the mask\n",
    "            if not env.mask[0, action_id]:\n",
    "                continue\n",
    "            \n",
    "            # Calculate the log probability of taking this action\n",
    "            action_log_prob = dist.log_prob(torch.tensor(action_id)).item()\n",
    "            new_total_log_prob = current_log_prob + action_log_prob\n",
    "\n",
    "            # If it's the 'end' action, it's a terminal state\n",
    "            if action_id == end_action_id:\n",
    "                kernel_str = str(env.state[0])\n",
    "                if terminal_states_data[kernel_str]['reward'] == 0.0:\n",
    "                    reward = log_likelihood_reward(X, Y, env).item()\n",
    "                    terminal_states_data[kernel_str]['reward'] = reward\n",
    "                \n",
    "                terminal_states_data[kernel_str]['policy_prob'] += torch.exp(torch.tensor(new_total_log_prob)).item()\n",
    "            else:\n",
    "                # If not 'end', take a step and recurse\n",
    "                # Create a copy of the environment state to explore this branch\n",
    "                next_env = deepcopy(env)\n",
    "                next_env.apply(torch.tensor([action_id]))\n",
    "                _enumerate_and_calc_probs(next_env, new_total_log_prob)\n",
    "\n",
    "    # To use the above function, you'll need to slightly modify your ForwardPolicy\n",
    "    # to return the raw logits for all actions, not just the sampled one.\n",
    "    # Let's assume a modified forward function like this:\n",
    "    # def forward(self, batch_state, actions=None):\n",
    "    #     ...\n",
    "    #     # After applying mask\n",
    "    #     return actions, log_probs.squeeze(), logits, state_flow.squeeze()\n",
    "    \n",
    "    # Start the recursion from the initial state\n",
    "    initial_env = env_class(batch_size=1, max_trajectory_length=max_len, log_reward=None)\n",
    "    _enumerate_and_calc_probs(initial_env, 0.0) # Start with log_prob = 0 (i.e., prob = 1)\n",
    "\n",
    "    # --- Post-processing ---\n",
    "    \n",
    "    # 1. Extract rewards and policy probabilities\n",
    "    rewards = np.array([data['reward'] for data in terminal_states_data.values()])\n",
    "    policy_probs = np.array([data['policy_prob'] for data in terminal_states_data.values()])\n",
    "\n",
    "    # 2. Calculate the Target Distribution P_T\n",
    "    partition_Z = np.sum(rewards)\n",
    "    if partition_Z == 0: return np.sum(policy_probs) # Should not happen if rewards are > 0\n",
    "    target_dist = rewards / partition_Z\n",
    "\n",
    "    # 3. Normalize the Policy Distribution P_theta\n",
    "    # The sum of policy_probs should be close to 1.0 if all paths are explored.\n",
    "    # Normalizing handles any minor floating point errors or unexplored paths.\n",
    "    policy_dist_sum = np.sum(policy_probs)\n",
    "    if policy_dist_sum == 0: return np.sum(target_dist) # No paths found\n",
    "    policy_dist = policy_probs / policy_dist_sum\n",
    "\n",
    "    # 4. Compute L1 Distance\n",
    "    l1_distance = np.sum(np.abs(target_dist - policy_dist))\n",
    "    \n",
    "    return l1_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = calculate_l1_distance(gflownet.forward_flow , KernelEnvironment, 4, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a690d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward calls: 2300\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total reward calls: {len(utils._likelihood_cache)}\")\n",
    "#utils._likelihood_cache = {}  # Clear the cache after sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c01e680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
